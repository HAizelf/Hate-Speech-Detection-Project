{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6232726f1442448b9d0ee06ca0b1c42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4116a7d18e447a186d1cc8f9d71830c",
              "IPY_MODEL_f9d0602b35d04858ab2ce5973378aceb",
              "IPY_MODEL_856f3a549a764119beb965a07e5a7b75"
            ],
            "layout": "IPY_MODEL_55a63e76bcfa48168f3d12c1eb21b49d"
          }
        },
        "f4116a7d18e447a186d1cc8f9d71830c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7868519ed5e94e68a6b6a9f43011ae5d",
            "placeholder": "​",
            "style": "IPY_MODEL_cc85a8d559e5435eae589c03712d6d05",
            "value": "Downloading: 100%"
          }
        },
        "f9d0602b35d04858ab2ce5973378aceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c33af3b46e54faf857babe90781eec6",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4f10e3871da487882fba345a4259ed7",
            "value": 501200538
          }
        },
        "856f3a549a764119beb965a07e5a7b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea792f2cff14ac3821fe5116c5d238f",
            "placeholder": "​",
            "style": "IPY_MODEL_b8e4aba680aa4375aea23237c5126a6d",
            "value": " 501M/501M [00:08&lt;00:00, 59.7MB/s]"
          }
        },
        "55a63e76bcfa48168f3d12c1eb21b49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7868519ed5e94e68a6b6a9f43011ae5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc85a8d559e5435eae589c03712d6d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c33af3b46e54faf857babe90781eec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f10e3871da487882fba345a4259ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ea792f2cff14ac3821fe5116c5d238f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e4aba680aa4375aea23237c5126a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0FLGSLzWd5c",
        "outputId": "863ce039-30f5-46d9-8de1-5040e093f767"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 13.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing libraries"
      ],
      "metadata": {
        "id": "xFJABBecWX5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IhFGH6U2oeWg"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report,accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeYjy57jbdUF",
        "outputId": "60ecd0d4-97ca-447f-d671-0e75290a53d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading dataset"
      ],
      "metadata": {
        "id": "2T1lbjxAWWCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/NLP /Project/H2_Hate_Offensive_Language_Identification_train.csv')"
      ],
      "metadata": {
        "id": "KRphV6HUxkSe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXasHw_ZDq9p",
        "outputId": "7fbd85b2-0c0d-43e5-80a2-0105681a90bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7593 entries, 0 to 7592\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    7593 non-null   object\n",
            " 1   label   7593 non-null   object\n",
            " 2   id      7593 non-null   int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 178.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb-h5e-oDgoz",
        "outputId": "3d684551-5f24-4342-ed7f-10f976ae65c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NOT', 'HOF'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "f945xoowDtQU",
        "outputId": "236c14d3-985d-413b-f7af-5869aa002289"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text label    id\n",
              "0     ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 क...   NOT     0\n",
              "1     @Raghuveerdutt62 @Arunesh24797107 रघुवीर जी यह...   NOT     1\n",
              "2     @Drmahera552 @common000786 मोदी तुम इस्तीफा दो...   NOT     2\n",
              "3     @sab_hateDMS Does she wear mesh hooker hose an...   HOF     3\n",
              "4     What a bunch of absolute fucking idiots in #in...   HOF     4\n",
              "...                                                 ...   ...   ...\n",
              "7588  @NewsNationTV दीपक जी! आज के विपक्षी दल जनता क...   HOF  7588\n",
              "7589  @pranaypiyush @ndtv That not gonna help india ...   NOT  7589\n",
              "7590  @ABPNews इसमें विवादित क्या है ? ताड़का बेहतर ...   HOF  7590\n",
              "7591  मक़तल में आ गया हूं तेरा साथ चाहता हूं तदफी़न ...   NOT  7591\n",
              "7592  Enough is enough   Thanks for your \"ACCHE DIN\"...   NOT  7592\n",
              "\n",
              "[7593 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-308f6672-58ba-4d10-b157-9576c3db951e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 क...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Raghuveerdutt62 @Arunesh24797107 रघुवीर जी यह...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Drmahera552 @common000786 मोदी तुम इस्तीफा दो...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sab_hateDMS Does she wear mesh hooker hose an...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What a bunch of absolute fucking idiots in #in...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7588</th>\n",
              "      <td>@NewsNationTV दीपक जी! आज के विपक्षी दल जनता क...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>7588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7589</th>\n",
              "      <td>@pranaypiyush @ndtv That not gonna help india ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>7589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7590</th>\n",
              "      <td>@ABPNews इसमें विवादित क्या है ? ताड़का बेहतर ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>7590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7591</th>\n",
              "      <td>मक़तल में आ गया हूं तेरा साथ चाहता हूं तदफी़न ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>7591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7592</th>\n",
              "      <td>Enough is enough   Thanks for your \"ACCHE DIN\"...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>7592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7593 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-308f6672-58ba-4d10-b157-9576c3db951e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-308f6672-58ba-4d10-b157-9576c3db951e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-308f6672-58ba-4d10-b157-9576c3db951e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].astype('category')\n",
        "df['label'] = df['label'].cat.codes\n",
        "df['label'] = df['label'].astype(np.int64)"
      ],
      "metadata": {
        "id": "4Vk9GjavW-bV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PyLggYKlF8YB",
        "outputId": "652deae5-eb9e-461c-a572-973194c6803a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label    id\n",
              "0     ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 क...      1     0\n",
              "1     @Raghuveerdutt62 @Arunesh24797107 रघुवीर जी यह...      1     1\n",
              "2     @Drmahera552 @common000786 मोदी तुम इस्तीफा दो...      1     2\n",
              "3     @sab_hateDMS Does she wear mesh hooker hose an...      0     3\n",
              "4     What a bunch of absolute fucking idiots in #in...      0     4\n",
              "...                                                 ...    ...   ...\n",
              "7588  @NewsNationTV दीपक जी! आज के विपक्षी दल जनता क...      0  7588\n",
              "7589  @pranaypiyush @ndtv That not gonna help india ...      1  7589\n",
              "7590  @ABPNews इसमें विवादित क्या है ? ताड़का बेहतर ...      0  7590\n",
              "7591  मक़तल में आ गया हूं तेरा साथ चाहता हूं तदफी़न ...      1  7591\n",
              "7592  Enough is enough   Thanks for your \"ACCHE DIN\"...      1  7592\n",
              "\n",
              "[7593 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-697c7681-e9bd-47ed-9b8d-b82d6fa2447f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 क...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Raghuveerdutt62 @Arunesh24797107 रघुवीर जी यह...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Drmahera552 @common000786 मोदी तुम इस्तीफा दो...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sab_hateDMS Does she wear mesh hooker hose an...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What a bunch of absolute fucking idiots in #in...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7588</th>\n",
              "      <td>@NewsNationTV दीपक जी! आज के विपक्षी दल जनता क...</td>\n",
              "      <td>0</td>\n",
              "      <td>7588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7589</th>\n",
              "      <td>@pranaypiyush @ndtv That not gonna help india ...</td>\n",
              "      <td>1</td>\n",
              "      <td>7589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7590</th>\n",
              "      <td>@ABPNews इसमें विवादित क्या है ? ताड़का बेहतर ...</td>\n",
              "      <td>0</td>\n",
              "      <td>7590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7591</th>\n",
              "      <td>मक़तल में आ गया हूं तेरा साथ चाहता हूं तदफी़न ...</td>\n",
              "      <td>1</td>\n",
              "      <td>7591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7592</th>\n",
              "      <td>Enough is enough   Thanks for your \"ACCHE DIN\"...</td>\n",
              "      <td>1</td>\n",
              "      <td>7592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7593 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-697c7681-e9bd-47ed-9b8d-b82d6fa2447f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-697c7681-e9bd-47ed-9b8d-b82d6fa2447f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-697c7681-e9bd-47ed-9b8d-b82d6fa2447f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df['text'].values)\n",
        "y = list(df['label'].values)"
      ],
      "metadata": {
        "id": "6o0JNhmTYELZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tmp, X_test, y_tmp, y_test = train_test_split(X, y, test_size = 0.10, random_state=42,stratify=y)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_tmp, y_tmp, test_size = 0.111, random_state=42,stratify=y_tmp)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_valid))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM0CZDHjY1Fz",
        "outputId": "6ec5cd32-7140-4893-edb0-29c8cffe8746"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6074\n",
            "759\n",
            "760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FKrPQ4eYKoy",
        "outputId": "1d10b3b2-96f8-4365-b589-25584f22e798"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-processing the whole dataset"
      ],
      "metadata": {
        "id": "HKzIhfbi2Izs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df.text.astype(str)"
      ],
      "metadata": {
        "id": "SZs4TKlS3Y97"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8xElFKj3emK",
        "outputId": "8351ef13-d473-4c3c-ca0a-2baa078d010d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 52.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import contractions\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords,wordnet\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer,TreebankWordTokenizer\n",
        "from nltk.tokenize import wordpunct_tokenize,TweetTokenizer\n",
        "\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW0o_Imp2INS",
        "outputId": "5d30bf97-a87d-4d39-a23e-3007ec8e3688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect\n",
        "from autocorrect import Speller\n",
        "spell = Speller(lang='en')\n",
        "def autospell(text):\n",
        "    spells = [spell(w) for w in (nltk.word_tokenize(text))]\n",
        "    return \" \".join(spells)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IexzyDd3T0l",
        "outputId": "722391d0-3a45-4ade-8421-7d0fee8c7d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 5.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=b5e891a6e6282d19e8cb13763e5b1fac9cec46d6355e786237a50d575f726cd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_tagger(tag):\n",
        "    nltk_tag=tag[1]\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV   \n",
        "    return 'n'"
      ],
      "metadata": {
        "id": "60IlXuZd3SO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_list=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\\\n",
        "     'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \\\n",
        "     'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\\\n",
        "    'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'if', 'or', 'because', 'as', 'until','of', 'at', 'by', 'for', 'with', 'about', 'between',\\\n",
        "    'into', 'through', 'during', 'to', 'from','in', 'out','on','again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', \n",
        "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', \n",
        "    'just','should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y','u','im','go','will','come','whats','twitter','tweet',\\\n",
        "    'know','x','yeah','year','yet','youre','would','do','can','nan','see','look','one','could','तुम','मेरी','मुझे','क्योंकि','हम','प्रति','अबकी','आगे','माननीय','शहर','बताएं','कौनसी','क्लिक','किसकी','बड़े','मैं','and','रही','आज','लें','आपके','मिलकर','सब','मेरे','जी','श्री','वैसा','आपका','अंदर', 'अत', 'अपना', 'अपनी', 'अपने', 'अभी', 'आदि', 'आप', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकी', 'इसके', 'इसमें', 'इसी', 'इसे', 'उन', 'उनका', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'ऐसे', 'और', 'कई', 'कर','करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफ़ी', 'कि', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोई', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जा', 'जितना', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जैसा', 'जैसे', 'जो', 'तक', 'तब', 'तरह', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'तो', 'था', 'थी', 'थे', 'दबारा', 'दिया', 'दुसरा', 'दूसरे', 'दो', 'द्वारा', 'न', 'नहीं', 'ना', 'निहायत', 'नीचे', 'ने', 'पर', 'पर', 'पहले', 'पूरा', 'पे', 'फिर', 'बनी', 'बही', 'बहुत', 'बाद', 'बाला', 'बिलकुल', 'भी', 'भीतर', 'मगर', 'मानो', 'मे', 'में', 'यदि', 'यह', 'यहाँ', 'यही', 'या', 'यिह', 'ये', 'रखें', 'रहा', 'रहे', 'ऱ्वासा', 'लिए', 'लिये', 'लेकिन', 'व', 'वर्ग', 'वह', 'वह', 'वहाँ', 'वहीं', 'वाले', 'वुह', 'वे', 'वग़ैरह', 'संग', 'सकता', 'सकते', 'सबसे', 'सभी', 'साथ', 'साबुत', 'साभ', 'सारा', 'से', 'सो', 'ही', 'हुआ', 'हुई', 'हुए', 'है', 'हैं', 'हो', 'होता', 'होती', 'होते', 'होना', 'होने', 'अपनि', 'जेसे', 'होति', 'सभि', 'तिंहों', 'इंहों', 'दवारा', 'इसि', 'किंहें', 'थि', 'उंहों', 'ओर', 'जिंहें', 'वहिं', 'अभि', 'बनि', 'हि', 'उंहिं', 'उंहें', 'हें', 'वगेरह', 'एसे', 'रवासा', 'कोन', 'निचे', 'काफि', 'उसि', 'पुरा', 'भितर', 'हे', 'बहि', 'वहां', 'कोइ', 'यहां', 'जिंहों', 'तिंहें', 'किसि', 'कइ', 'यहि', 'इंहिं', 'जिधर', 'इंहें', 'अदि', 'इतयादि', 'हुइ', 'कोनसा', 'इसकि', 'दुसरे', 'जहां', 'अप', 'किंहों', 'उनकि', 'भि', 'वरग', 'हुअ', 'जेसा', 'नहिं']\n",
        "\n",
        "stop_reg = r'\\b(?:'+'|'.join(stop_list)+r')\\b'\n",
        "stop_reg\n",
        "stopword_finder= re.compile(stop_reg)"
      ],
      "metadata": {
        "id": "T4KrW5U7xrvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processing(sentence, verbose=False):\n",
        "  og_sentence = sentence\n",
        "  sentence=sentence.lower()#CASE FOLDING\n",
        "  html_finder = re.compile(r'<.*?>|&\\w+;')\n",
        "  rmhtml_Text=html_finder.sub('',sentence)  #remove HTML Tags\n",
        "  # rmurl_Text = re.sub(r'http\\S+|https:\\S+|www\\S+|.com\\S+', '', rmhtml_Text) #remove URL tags\n",
        "  pre_url = r'(?:https?://)|(?:www\\.)'\n",
        "  url_set = r'[\\w+=?/._\\-:;&*^$#@~`!|]'\n",
        "  rmurl_Text=re.sub(f'(?:{pre_url}){url_set}+|{url_set}+\\.com{url_set}*', '',rmhtml_Text)\n",
        "  username_finder = re.compile('@\\w+')\n",
        "  rmurl_Text=username_finder.sub('',rmurl_Text) #remove usernames\n",
        "  rmwhite_Text=re.sub(' +', ' ',rmurl_Text) #remove extra whitespace\n",
        "  rmwhite_Text = contractions.fix(rmwhite_Text) #Remove contractions\n",
        "  rmpunt_text=re.sub('[^\\w\\s]','',rmwhite_Text) #punctuation and username removal\n",
        "  \n",
        "  token_text=[token for token in TweetTokenizer().tokenize(rmpunt_text)]#tokenize text \n",
        "  \n",
        "  # stem_text= [stemmer.stem(word) for word in rmpunt_text]#stemming\n",
        "  pos_tags=[pos_tagger(tag) for tag in nltk.pos_tag(token_text)]\n",
        "  lem_text= [lemmatizer.lemmatize(word,pos=pos) for word,pos in zip(token_text,pos_tags)] #lemmatize word\n",
        "  # print(lem_text)\n",
        "  rmstop_text = [tok for tok in lem_text if not stopword_finder.search(tok)]\n",
        "  # print(rmstop_text)\n",
        "  sentence=TreebankWordDetokenizer().detokenize(rmstop_text) #convert to sentence \n",
        "  spell_sentence = autospell(sentence)\n",
        "  if verbose:\n",
        "    print(f'Original sentence :\\n{og_sentence}\\n')\n",
        "    print(f'Removing HTML and (Lowercasing):\\n{rmhtml_Text}\\n')\n",
        "    print(f'Removing URL tags (and usernames):\\n{rmurl_Text}\\n')\n",
        "    print(f'Removing whitespace(and expand contractions):\\n{rmwhite_Text}\\n')\n",
        "    print(f'Remove punctuations:\\n{rmpunt_text}\\n')   \n",
        "    print(f'Tokenize Text:\\n{token_text}\\n')\n",
        "    print(f'Lemmatize Text:\\n{lem_text}\\n')\n",
        "    print(f'Removing stop words Text:\\n{rmstop_text}\\n')\n",
        "    print(f'Spelling Correction:\\n{spell_sentence}\\n')\n",
        "  \n",
        "  return spell_sentence"
      ],
      "metadata": {
        "id": "jiY1ubdg3vKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Stephanie Pratt Tells MTV News 'The Hills' Did Not Make Me Bulimic' \\\n",
        "    http://bit.ly/n4wL4 BETTER but still > half the story is missing\" \n",
        "text=df['text'][0]\n",
        "\n",
        "processing(text,verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "svWRI4bU3vhX",
        "outputId": "5266543d-270a-41a1-eb69-172c40896145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence :\n",
            "ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 का गंभीर मरीज बिना ऑक्सीजन सपोर्ट के अस्पताल नहीं लाया जा सकता है. इसलिए मैंने सोचा ऑटोरिक्शा को एंबुलेंस में क्यों ना बदल डालूं.\" #IndiaCovidCrisis #OxygenCrisis   https://t.co/F1snlleyMP\n",
            "\n",
            "Removing HTML and (Lowercasing):\n",
            "ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 का गंभीर मरीज बिना ऑक्सीजन सपोर्ट के अस्पताल नहीं लाया जा सकता है. इसलिए मैंने सोचा ऑटोरिक्शा को एंबुलेंस में क्यों ना बदल डालूं.\" #indiacovidcrisis #oxygencrisis   https://t.co/f1snlleymp\n",
            "\n",
            "Removing URL tags (and usernames):\n",
            "ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 का गंभीर मरीज बिना ऑक्सीजन सपोर्ट के अस्पताल नहीं लाया जा सकता है. इसलिए मैंने सोचा ऑटोरिक्शा को एंबुलेंस में क्यों ना बदल डालूं.\" #indiacovidcrisis #oxygencrisis   \n",
            "\n",
            "Removing whitespace(and expand contractions):\n",
            "ऑटोरिक्शा चालक जावेद खान कहते हैं, \"कोविड-19 का गंभीर मरीज बिना ऑक्सीजन सपोर्ट के अस्पताल नहीं लाया जा सकता है. इसलिए मैंने सोचा ऑटोरिक्शा को एंबुलेंस में क्यों ना बदल डालूं.\" #indiacovidcrisis #oxygencrisis \n",
            "\n",
            "Remove punctuations:\n",
            "ऑटरकश चलक जवद खन कहत ह कवड19 क गभर मरज बन ऑकसजन सपरट क असपतल नह लय ज सकत ह इसलए मन सच ऑटरकश क एबलस म कय न बदल डल indiacovidcrisis oxygencrisis \n",
            "\n",
            "Tokenize Text:\n",
            "['ऑटरकश', 'चलक', 'जवद', 'खन', 'कहत', 'ह', 'कवड', '19', 'क', 'गभर', 'मरज', 'बन', 'ऑकसजन', 'सपरट', 'क', 'असपतल', 'नह', 'लय', 'ज', 'सकत', 'ह', 'इसलए', 'मन', 'सच', 'ऑटरकश', 'क', 'एबलस', 'म', 'कय', 'न', 'बदल', 'डल', 'indiacovidcrisis', 'oxygencrisis']\n",
            "\n",
            "Lemmatize Text:\n",
            "['ऑटरकश', 'चलक', 'जवद', 'खन', 'कहत', 'ह', 'कवड', '19', 'क', 'गभर', 'मरज', 'बन', 'ऑकसजन', 'सपरट', 'क', 'असपतल', 'नह', 'लय', 'ज', 'सकत', 'ह', 'इसलए', 'मन', 'सच', 'ऑटरकश', 'क', 'एबलस', 'म', 'कय', 'न', 'बदल', 'डल', 'indiacovidcrisis', 'oxygencrisis']\n",
            "\n",
            "Removing stop words Text:\n",
            "['ऑटरकश', 'चलक', 'जवद', 'खन', 'कहत', 'ह', 'कवड', '19', 'क', 'गभर', 'मरज', 'बन', 'ऑकसजन', 'सपरट', 'क', 'असपतल', 'नह', 'लय', 'ज', 'सकत', 'ह', 'इसलए', 'मन', 'सच', 'ऑटरकश', 'क', 'एबलस', 'म', 'कय', 'बदल', 'डल', 'indiacovidcrisis', 'oxygencrisis']\n",
            "\n",
            "Spelling Correction:\n",
            "ऑटरकश चलक जवद खन कहत ह कवड 19 क गभर मरज बन ऑकसजन सपरट क असपतल नह लय ज सकत ह इसलए मन सच ऑटरकश क एबलस म कय बदल डल indiacovidcrisis oxygencrisis\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ऑटरकश चलक जवद खन कहत ह कवड 19 क गभर मरज बन ऑकसजन सपरट क असपतल नह लय ज सकत ह इसलए मन सच ऑटरकश क एबलस म कय बदल डल indiacovidcrisis oxygencrisis'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.apply(lambda row: processing(row.text,verbose=False),axis=1)"
      ],
      "metadata": {
        "id": "6qtcgzgm3y5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['new_text']=data"
      ],
      "metadata": {
        "id": "92XkmQhq4FOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/NLP /Project/H2_Hate_Offensive_Language_Identification_train_processed.csv')"
      ],
      "metadata": {
        "id": "BSyo39Mgant8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['new_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSZl1LoMavlk",
        "outputId": "bf2d8d7c-3327-482c-d6ed-8b4f706c86c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       ऑटरकश चलक जवद खन कहत ह कवड 19 क गभर मरज बन ऑकस...\n",
              "1       रघवर ज यह सतय ह क वनर कई बडबड बल वल पछ वल जनवर...\n",
              "2       मद तम इसतफ द हम तमहर सथ ह resignmodi resign_pm...\n",
              "3             wear mesh hooker hose phd community college\n",
              "4       bunch absolute fuck idiot india indiacovidcris...\n",
              "                              ...                        \n",
              "7588    दपक ज आज क वपकष दल जनत क परशन करक सतत म आन चहत...\n",
              "7589    not help india anyway but mean image chinesevirus\n",
              "7590    इसम ववदत कय ह तडक बहतर थ जहद नह कय थ उसन उस और...\n",
              "7591    मकतल म आ गय ह तर सथ चहत ह तदफन ह रह ह तर सथ चह...\n",
              "7592    enough enough thanks cache din resignpmmodi no...\n",
              "Name: new_text, Length: 7593, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_hi = ['तुम','मेरी','मुझे','क्योंकि','हम','प्रति','अबकी','आगे','माननीय','शहर','बताएं','कौनसी','क्लिक','किसकी','बड़े','मैं','and','रही','आज','लें','आपके','मिलकर','सब','मेरे','जी','श्री','वैसा','आपका','अंदर', 'अत', 'अपना', 'अपनी', 'अपने', 'अभी', 'आदि', 'आप', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकी', 'इसके', 'इसमें', 'इसी', 'इसे', 'उन', 'उनका', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'ऐसे', 'और', 'कई', 'कर','करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफ़ी', 'कि', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोई', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जा', 'जितना', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जैसा', 'जैसे', 'जो', 'तक', 'तब', 'तरह', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'तो', 'था', 'थी', 'थे', 'दबारा', 'दिया', 'दुसरा', 'दूसरे', 'दो', 'द्वारा', 'न', 'नहीं', 'ना', 'निहायत', 'नीचे', 'ने', 'पर', 'पर', 'पहले', 'पूरा', 'पे', 'फिर', 'बनी', 'बही', 'बहुत', 'बाद', 'बाला', 'बिलकुल', 'भी', 'भीतर', 'मगर', 'मानो', 'मे', 'में', 'यदि', 'यह', 'यहाँ', 'यही', 'या', 'यिह', 'ये', 'रखें', 'रहा', 'रहे', 'ऱ्वासा', 'लिए', 'लिये', 'लेकिन', 'व', 'वर्ग', 'वह', 'वह', 'वहाँ', 'वहीं', 'वाले', 'वुह', 'वे', 'वग़ैरह', 'संग', 'सकता', 'सकते', 'सबसे', 'सभी', 'साथ', 'साबुत', 'साभ', 'सारा', 'से', 'सो', 'ही', 'हुआ', 'हुई', 'हुए', 'है', 'हैं', 'हो', 'होता', 'होती', 'होते', 'होना', 'होने', 'अपनि', 'जेसे', 'होति', 'सभि', 'तिंहों', 'इंहों', 'दवारा', 'इसि', 'किंहें', 'थि', 'उंहों', 'ओर', 'जिंहें', 'वहिं', 'अभि', 'बनि', 'हि', 'उंहिं', 'उंहें', 'हें', 'वगेरह', 'एसे', 'रवासा', 'कोन', 'निचे', 'काफि', 'उसि', 'पुरा', 'भितर', 'हे', 'बहि', 'वहां', 'कोइ', 'यहां', 'जिंहों', 'तिंहें', 'किसि', 'कइ', 'यहि', 'इंहिं', 'जिधर', 'इंहें', 'अदि', 'इतयादि', 'हुइ', 'कोनसा', 'इसकि', 'दुसरे', 'जहां', 'अप', 'किंहों', 'उनकि', 'भि', 'वरग', 'हुअ', 'जेसा', 'नहिं']"
      ],
      "metadata": {
        "id": "472BvTDIaxfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3AgSr9M_n17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Repo"
      ],
      "metadata": {
        "id": "E9uSEMtnC-Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'roberta-base'\n",
        "def generate_dataset(X,y, tokenizer):\n",
        "\n",
        "  #Generate encodings\n",
        "  encodings = tokenizer.batch_encode_plus(X,        \n",
        "                                          truncation = True,\n",
        "                                          padding=True,\n",
        "                                          max_length=128,\n",
        "                                          return_tensors='pt',\n",
        "                                          add_special_tokens = True)\n",
        "\n",
        "  #convert to tensor dataset\n",
        "  input_ids = encodings['input_ids']\n",
        "  attention_mask = encodings['attention_mask']\n",
        "\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "  y = torch.tensor(y)\n",
        "\n",
        "  dataset = TensorDataset(input_ids,attention_mask,y)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "BV1UK2VEC_1j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "train_dataset = generate_dataset(X_train,y_train,tokenizer)\n",
        "valid_dataset = generate_dataset(X_valid,y_valid,tokenizer)"
      ],
      "metadata": {
        "id": "Ci7v4rOsYq6h"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset,sampler):\n",
        "  return DataLoader(dataset=dataset,sampler=sampler(dataset),batch_size=32)"
      ],
      "metadata": {
        "id": "gv6EWCn5Y8Ib"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = get_data_loader(train_dataset,RandomSampler)\n",
        "validation_loader = get_data_loader(valid_dataset,SequentialSampler)"
      ],
      "metadata": {
        "id": "_afs3xevY-RH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.cuda()\n",
        "print(\"Imported model!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "6232726f1442448b9d0ee06ca0b1c42b",
            "f4116a7d18e447a186d1cc8f9d71830c",
            "f9d0602b35d04858ab2ce5973378aceb",
            "856f3a549a764119beb965a07e5a7b75",
            "55a63e76bcfa48168f3d12c1eb21b49d",
            "7868519ed5e94e68a6b6a9f43011ae5d",
            "cc85a8d559e5435eae589c03712d6d05",
            "9c33af3b46e54faf857babe90781eec6",
            "c4f10e3871da487882fba345a4259ed7",
            "5ea792f2cff14ac3821fe5116c5d238f",
            "b8e4aba680aa4375aea23237c5126a6d"
          ]
        },
        "id": "AvTcGO4nZA9P",
        "outputId": "35699c52-8afd-4b5c-f68c-db062eeaee7c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6232726f1442448b9d0ee06ca0b1c42b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-8)\n",
        "\n",
        "num_epochs = 8\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "def compute_accuracy(preds,labels):\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  labels = labels.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds,axis=1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  return np.sum(preds == labels)/len(labels)\n",
        "import random\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "Vw24Vot-ZPCB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  num_steps = 0\n",
        "\n",
        "  for step,batch in enumerate(train_loader):\n",
        "    \n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_loader)))\n",
        "\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    outputs = model(input_ids,attention_mask = attention_mask,labels = labels.long())\n",
        "    \n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "    total_acc = total_acc + compute_accuracy(logits,labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "  avg_loss = total_loss/len(train_loader)\n",
        "  avg_acc = total_acc/len(train_loader)\n",
        "\n",
        "  return avg_loss,avg_acc\n"
      ],
      "metadata": {
        "id": "AHhSESmtZOw1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  true_labels = []\n",
        "  predictions = []\n",
        "\n",
        "  for step,batch in enumerate(validation_loader):\n",
        "    \n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(validation_loader)))\n",
        "\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(input_ids,attention_mask = attention_mask,labels = labels.long())\n",
        "    \n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "    total_acc = total_acc + compute_accuracy(logits,labels)\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    logits = np.argmax(logits,axis=1).flatten()\n",
        "    labels = labels.detach().cpu().numpy().flatten()\n",
        "\n",
        "    true_labels.extend(labels)\n",
        "    predictions.extend(logits)\n",
        "\n",
        "  avg_loss = total_loss/len(validation_loader)\n",
        "  avg_acc = total_acc/len(validation_loader)\n",
        "  macro_f1_score =  classification_report(true_labels, predictions,output_dict=True)['macro avg']['f1-score']\n",
        "\n",
        "  return avg_loss,avg_acc,macro_f1_score"
      ],
      "metadata": {
        "id": "juwsJmJOZYOU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "\n",
        "best_f1 = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print('\\n Epoch {:} / {:}'.format(epoch + 1, num_epochs))\n",
        "  \n",
        "  train_loss, train_acc = train()\n",
        "  valid_loss, valid_acc,f1_score = evaluate()\n",
        "\n",
        "  train_losses.append(train_loss)\n",
        "  train_accs.append(train_acc)\n",
        "  valid_losses.append(valid_loss)\n",
        "  valid_accs.append(valid_acc)\n",
        "\n",
        "  if f1_score > best_f1:\n",
        "      best_f1 = f1_score\n",
        "      torch.save(model,'/content/drive/MyDrive/NLP /Project/final_english_model_robert_8Sept.pt')\n",
        "\n",
        "\n",
        "  print(f'\\nTraining Accuracy: {train_acc:.3f} | Training Loss: {train_loss:.3f} | Validation Accuracy: {valid_acc:.3f} | Validation Loss: {valid_loss:.3f} | F1 Score: {f1_score:3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8mYe3kNZdyJ",
        "outputId": "63faf87a-c565-4e15-ac0a-e2119243a491"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.699 | Training Loss: 0.583 | Validation Accuracy: 0.740 | Validation Loss: 0.525 | F1 Score: 0.728081\n",
            "\n",
            " Epoch 2 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.779 | Training Loss: 0.473 | Validation Accuracy: 0.801 | Validation Loss: 0.472 | F1 Score: 0.797429\n",
            "\n",
            " Epoch 3 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.817 | Training Loss: 0.410 | Validation Accuracy: 0.791 | Validation Loss: 0.496 | F1 Score: 0.789014\n",
            "\n",
            " Epoch 4 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.845 | Training Loss: 0.358 | Validation Accuracy: 0.780 | Validation Loss: 0.542 | F1 Score: 0.777572\n",
            "\n",
            " Epoch 5 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.871 | Training Loss: 0.307 | Validation Accuracy: 0.778 | Validation Loss: 0.539 | F1 Score: 0.769953\n",
            "\n",
            " Epoch 6 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.890 | Training Loss: 0.264 | Validation Accuracy: 0.774 | Validation Loss: 0.614 | F1 Score: 0.771153\n",
            "\n",
            " Epoch 7 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.901 | Training Loss: 0.237 | Validation Accuracy: 0.788 | Validation Loss: 0.622 | F1 Score: 0.783448\n",
            "\n",
            " Epoch 8 / 8\n",
            "  Batch    50  of    190.\n",
            "  Batch   100  of    190.\n",
            "  Batch   150  of    190.\n",
            "\n",
            "Training Accuracy: 0.909 | Training Loss: 0.219 | Validation Accuracy: 0.765 | Validation Loss: 0.678 | F1 Score: 0.763051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xGl_4x7zabmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Eval on Test"
      ],
      "metadata": {
        "id": "BWsoEFhhetYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = generate_dataset(X_test,y_test,tokenizer)\n",
        "test_loader = get_data_loader(test_dataset,SequentialSampler)\n",
        "model = torch.load('/content/drive/MyDrive/NLP /Project/final_english_model_robert_8Sept.pt')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "wXiV4jo-evRc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_evaluate(model):\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  true_labels = []\n",
        "  predictions = []\n",
        "\n",
        "  for step,batch in enumerate(test_loader):\n",
        "    \n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_loader)))\n",
        "\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(input_ids,attention_mask = attention_mask,labels = labels.long())\n",
        "    \n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "    total_acc = total_acc + compute_accuracy(logits,labels)\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    logits = np.argmax(logits,axis=1).flatten()\n",
        "    labels = labels.detach().cpu().numpy().flatten()\n",
        "\n",
        "    true_labels.extend(labels)\n",
        "    predictions.extend(logits)\n",
        "\n",
        "  avg_loss = total_loss/len(test_loader)\n",
        "  avg_acc = total_acc/len(test_loader)\n",
        "  macro_f1_score =  classification_report(true_labels, predictions,output_dict=True)['macro avg']['f1-score']\n",
        "\n",
        "  return avg_loss,avg_acc,macro_f1_score"
      ],
      "metadata": {
        "id": "a8RRR51zez4m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc,f1_score = test_evaluate(model)\n",
        "print(f'\\nTest Accuracy: {test_acc:.3f} | Test Loss: {test_loss:.3f} | F1 Score: {f1_score:.3f} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZuYfYvle2qa",
        "outputId": "7174e8d6-f47c-4bdc-df3d-2804b9c71127"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.789 | Test Loss: 0.451 | F1 Score: 0.787 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I7o4_Cofg9iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Actual test"
      ],
      "metadata": {
        "id": "jvKOvpGriwaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_set=pd.read_csv('/content/drive/MyDrive/NLP /Project/H2_Hate_Offensive_Language_Identification_test.csv')"
      ],
      "metadata": {
        "id": "ipRYyx0oiyOv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_set['labels']=list(np.ones(df_test_set['text'].values.shape[0]))"
      ],
      "metadata": {
        "id": "Z1x6rLEFlTr4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_set = list(df_test_set['text'].values)\n",
        "y_test_set = list(df_test_set['labels'].values)"
      ],
      "metadata": {
        "id": "tLHTdHe0i5qA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAED97fIkRvD",
        "outputId": "b2b0d9d3-27a4-4cb1-886f-e0d0b0d9973e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 844 entries, 0 to 843\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   text    844 non-null    object \n",
            " 1   id      844 non-null    int64  \n",
            " 2   labels  844 non-null    float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 19.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = generate_dataset(X_test_set,y_test_set,tokenizer)\n",
        "# test_loader = get_data_loader(test_dataset,SequentialSampler)\n",
        "test_loader=DataLoader(dataset=test_dataset,batch_size=1,shuffle=False)\n",
        "model = torch.load('/content/drive/MyDrive/NLP /Project/final_english_model_robert_8Sept.pt')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "1N530ssvnKx-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(model,test_loader):\n",
        "  model.train()\n",
        "    \n",
        "  true_labels = []\n",
        "  predictions = []\n",
        "  ids=[]\n",
        "  for step,batch in enumerate(test_loader):\n",
        "\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_loader)))\n",
        "\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(input_ids,attention_mask = attention_mask,labels = labels.long())\n",
        "    # import pdb; pdb.set_trace()\n",
        "    logits = outputs.logits\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    logits = np.argmax(logits,axis=1).flatten()\n",
        "    predictions.extend(logits)\n",
        "    # ids.extend(input_ids.detach().cpu().numpy())\n",
        "  df =pd.DataFrame()\n",
        "  df['label']=predictions\n",
        "  # df['id']=ids\n",
        "  return df"
      ],
      "metadata": {
        "id": "pyg2n6hTkVy8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df=generate_predictions(model,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGRNMfz4nS6E",
        "outputId": "ce53c339-f23f-4acb-c79d-a32a87921bde"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of    844.\n",
            "  Batch   100  of    844.\n",
            "  Batch   150  of    844.\n",
            "  Batch   200  of    844.\n",
            "  Batch   250  of    844.\n",
            "  Batch   300  of    844.\n",
            "  Batch   350  of    844.\n",
            "  Batch   400  of    844.\n",
            "  Batch   450  of    844.\n",
            "  Batch   500  of    844.\n",
            "  Batch   550  of    844.\n",
            "  Batch   600  of    844.\n",
            "  Batch   650  of    844.\n",
            "  Batch   700  of    844.\n",
            "  Batch   750  of    844.\n",
            "  Batch   800  of    844.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df['id']=list(df_test_set['id'].values)"
      ],
      "metadata": {
        "id": "84wpvQg3npwJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df.to_csv('/content/drive/MyDrive/NLP /Project/H2_Hate_Offensive_Language_Identification_test_predictions.csv')"
      ],
      "metadata": {
        "id": "GESuIQAtqCPE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bXsLYNtEmev"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}